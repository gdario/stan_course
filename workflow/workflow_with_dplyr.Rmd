---
title: "Workflow using dplyr"
author: "Giovanni d'Ario"
date: "9/11/2019"
output: html_document
---

```{r, echo=FALSE}
### Tidyverse libraries
library(magrittr)
library(tibble)
library(dplyr)
library(tidyr)
library(ggplot2)

### Parallel processing
library(foreach)
library(doParallel)

### rstan and utilities
library(rstan)
rstan_options(auto_write = TRUE)
util <- new.env()
source("stan_utility.R", local = util)

### My own utilities
source("utils.R")
```

We simulate 1000 draws from the 100 detectors.

```{r}
R <- 1000 # 1000 draws from the Bayesian joint distribution
N <- 100

simu_data <- list("N" = N)

fit <- stan(file = 'sample_joint_ensemble.stan', data = simu_data,
            iter = R, warmup = 0, chains = 1, refresh = R,
            seed = 4838282, algorithm = "Fixed_param")
```

The `fit` object contains the simulated `lambda`s and `y`s.

```{r}
simu_params <- extract(fit)
```

We can visualize the distribution of the values of `lambda` in a histogram.

```{r}
df_simu_ys <- data.frame(simu_params$y)
colnames(df_simu_ys) <- paste0("D", 1:100)
df_simu_ys$lambda <- simu_params$lambda

ggplot(df_simu_ys, aes(x = lambda)) + stat_bin(geom = "step")
```

This visualization, however, doesn't make things clearer. We can first bin the counts on each row, and then compute the quantiles for these counts.
We can then compute the quantiles of each bin across the 1000 runs. The black line represent the median.

```{r}
plot_bin_quantiles(simu_params$y) + 
  geom_vline(xintercept = 25, color = "darkgrey")
```

## Evaluate the simulated files

In this section we want to generate multiple *posterior* distributions (in the previous section we were only examining the prior predictive distribution). Once we have these multiple posterior distributions, we can apply posterior-based calibration and compute the $z$ score and the posterior shrinkage. We can start defining a helper function which computes the Simulation Based Calibration Rank `sbc_rank`, the Z score `z_score`, the posterior shrinkage `shrinkage` and, in addition, captures any warning message produced by the diagnostic checks. Note that in the Case Study the rank is computed on a thinned `lambda` vector (one element every 8), while here we consider all the elements.

```{r, eval=FALSE}
compute_metrics <- function(simu, 
                            N=N, 
                            model, 
                            thin=8, 
                            prior_sd_lambda=5.82337, 
                            seed=4938483) {
  simu_lambda <- simu[1]
  simu_y <- simu[-1]

  input_data <- list("N" = N, "y" = simu_y)

  capture.output(
    fit <- sampling(model, data = input_data, seed = seed)
  )

  ## Check if there are problematic cases
  util <- new.env()
  source("stan_utility.R", local = util)
  warning_code <- util$check_all_diagnostics(fit, quiet = TRUE)

  ## Simulation Based Calibration ranking
  lambda <- extract(fit)$lambda
  sbc_rank <- sum(simu_lambda < lambda[seq(1, length(lambda) - thin, thin)])

  ## Compute posterior sensitivities
  s <- summary(fit, probs = c(), pars = "lambda")$summary
  post_mean_lambda <- s[, 1]
  post_sd_lambda <- s[, 3]

  z_score <- (post_mean_lambda - simu_lambda) / post_sd_lambda
  shrinkage <- 1 - (post_sd_lambda / prior_sd_lambda)**2

  c(warning_code, sbc_rank, z_score, shrinkage)
}
```

We can run the above function in parallel on all the available cores.

```{r}
tryCatch({
  ## Register doParallel
  registerDoParallel(cores = detectCores())
  
  ## Create a data frame of simulated lambdas and ys
  ## data.matrix converts a data frame into a matrix
  simu_list <- t(data.matrix(data.frame(
    remove_lp__(simu_params)))
  )

  ## Fit the model that computes the posterior density (we need to do it once).
  fit_model = stan_model(file = 'fit_data.stan')

  ensemble_output <- foreach(simu = simu_list, .combine = "cbind") %dopar% {
    get_sbc_parameters(sim_vector = simu,
                       model = fit_model,
                       param_names = "lambda",
                       prior_sd = 5.82337,
                       seed = 4938483,
                       N = N)
  }
}, finally = {stopImplicitCluster()})
```

The result is a 4 x 1000 matrix with, in order, the number of warnings, the rank the z score, and the shrinkage.

```{r}
print(dim(ensemble_output))
rownames(ensemble_output) <- c("num_warnings", "sbc_rank", "z_score", "shrinkage")
output_df <- data.frame(t(ensemble_output))
```

We can first check whether we have any warning message.

```{r}
sum(ensemble_output[1, ])
```

We have zero warnings. This is good. We can then plot a histogram of the SBC ranks using the same `breaks` as in the case study.

```{r}
ggplot(output_df, aes(sbc_rank)) +
  geom_histogram(color = c_dark_highlight, fill = c_dark,
                 breaks = seq(0, 500, 25) - 0.5) +
  xlab("Prior Rank") + ylab("")
```

Does it look like the histogram in the case study?

```{r}
sbc_hist <- hist(output_df$sbc_rank,
                 seq(0, 500, 25) - 0.5,
                 plot = FALSE)

plot(sbc_hist, main = "Lambda", xlab = "Prior Rank", yaxt = 'n', ylab = "")

low <- qbinom(0.005, R, 1 / 20)
mid <- qbinom(0.5, R, 1 / 20)
high <- qbinom(0.995, R, 1 / 20)
bar_x <- c(-10, 510, 500, 510,-10, 0,-10)
bar_y <- c(high, high, mid, low, low, mid, high)

polygon(bar_x, bar_y, col = c("#DDDDDD"), border = NA)
segments(x0 = 0, x1 = 500, y0 = mid, y1 = mid, col = c("#999999"), lwd = 2)

plot(sbc_hist, col = c_dark, border = c_dark_highlight, add = TRUE)
```

Yes, it does.

## Z scores and posterior shrinkage

We can plot the `z_score` vs the `shrinkage` and see where our simulations fall.

```{r}
ggplot(output_df, aes(x = shrinkage, y = z_score)) +
  geom_point(alpha = .1) +
  xlim(0, 1) + ylim(-4, 4)
```

**TO UNDERSTAND** how do you explain the shrinkage from the prior to the posterior?

## Fitting the observations an computing the posterior

The dataset consistes of 100 observations, one per detector.

```{r}
input_data <- read_rdump("workflow.data.R")
str(input_data)
```

We can then fit the observations with the following model

```{stan, eval=FALSE}
data {
  int<lower=0> N;
  int y[N];
}

parameters {
  real<lower=0> lambda;
}

model {
  lambda ~ normal(0, 5.82337);
  y ~ poisson(lambda);
}
```

```{r, message=FALSE}
fit <- stan(file = 'fit_data_ppc.stan', data = input_data, seed = 4938483)
```

```{r}
util$check_all_diagnostics(fit)
params <- extract(fit)
hist(params$lambda, main = "", xlab = "lambda", ylab = "",
     col = c_dark, border = c_dark_highlight)
```

## Analysis of the posterior predictive distribution

Running 4 chains has produced a 4000 x 100 matrix for `y_ppc`.

```{r}
p <- plot_bin_quantiles(params$y_ppc)
p + stat_bin(data = tibble(y_obs = input_data$y), aes(y_obs),
             breaks = 0:(41) - 0.5, geom = "step")
```

## Zero-inflated mode

The sampling model is stored in `sample_join_ensemble2.stan` while the data fitting model is in `fit_data2.stan`.

```{r}
fit <- stan(file = "sample_joint_ensemble2.stan", data = simu_data,
            iter = R, warmup = 0, chains = 1, refresh = R,
            seed = 4838282, algorithm = "Fixed_param")

simu_params <- extract(fit)
```

```{r}
plot_bin_quantiles(simu_params$y) +
  geom_vline(xintercept = 25, color = "darkgrey")
```

We can see the zero-enrichment in the prior predictive distribution, and the tails are unaltered.

## Simulated fits

```{r}
prior_sd_theta <- sqrt((2.8663**2) / (4*2.8663**2) * (2 * 2.8663 + 1))
prior_sd_lambda <- sqrt((9.21604)**2 / ((3.4681 - 1)**3))
  
tryCatch({
  ## Register doParallel
  registerDoParallel(cores = detectCores())
  
  ## Create a data frame of simulated lambdas and ys
  ## data.matrix converts a data frame into a matrix
  simu_list <- t(data.matrix(data.frame(
    remove_lp__(simu_params)))
  )

  ## Fit the model that computes the posterior density (we need to do it once).
  fit_model = stan_model(file = 'fit_data2.stan')

  ensemble_output <- foreach(simu = simu_list, .combine = "cbind") %dopar% {
    get_sbc_parameters(sim_vector = simu,
                       model = fit_model,
                       param_names = c("theta", "lambda"),
                       prior_sd = c(prior_sd_theta, prior_sd_lambda),
                       seed = 4938483,
                       N = N)
  }
}, finally = {stopImplicitCluster()})
```


Do we have warning codes? Yes we do:

```{r}
print(sum(ensemble_output[1, ]))
```

What kind of warnings do we get?

```{r what_warnings}
warning_code <- ensemble_output[1, ]
for (r in 1:R) {
  if (warning_code[r] != 0) {
    print(sprintf("Replication %s of %s", r, R))
    util$parse_warning_code(warning_code[r])
    print(sprintf("Simulated lambda = %s", simu_lambdas[r]))
    print(sprintf("Simulated theta = %s", simu_thetas[r]))
    print(" ")
  }
}
```

```{r fit_inv_gamma_simu}
fit <- stan(file = "sample_joint_ensemble3.stan", data = simu_data,
            iter = R, warmup = 0, chains = 1, refresh = R,
            seed = 4838282, algorithm = "Fixed_param")
simu_params <- rstan::extract(fit)
plot_bin_quantiles(simu_params$y, B = 70) +
  geom_vline(xintercept = 25, color = "darkgrey")
```


```{r}
prior_sd_theta <- sqrt(2.8663**2 / (4 * 2.8663**2 * (2 * 2.8663 + 1))) 
prior_sd_lambda <- sqrt((9.21604**2) / (3.48681 - 1)**3)

tryCatch({
  ## Register doParallel
  registerDoParallel(cores = detectCores())
  
  ## Create a data frame of simulated lambdas and ys
  ## data.matrix converts a data frame into a matrix
  simu_list <- t(data.matrix(data.frame(
    remove_lp__(simu_params)))
  )

  ## Fit the model that computes the posterior density (we need to do it once).
  fit_model = stan_model(file = 'fit_data3.stan')

  ensemble_output <- foreach(simu = simu_list, .combine = "cbind") %dopar% {
    get_sbc_parameters(sim_vector = simu,
                       model = fit_model,
                       param_names = c("theta", "lambda"),
                       prior_sd = c(prior_sd_theta, prior_sd_lambda),
                       seed = 4938483,
                       N = N)
  }
}, finally = {stopImplicitCluster()})
# 
# tryCatch({
#   registerDoParallel(cores = 4)
#   simu_list <- t(data.matrix(data.frame(simu_lambdas, simu_thetas, simu_ys)))
#   fit_model <- stan_model(file = "fit_data3.stan")
#   ensemble_output <- foreach(simu = simu_list, .combine = "cbind") %dopar% {
#     
#     simu_lambda <- simu[1]
#     simu_theta <- simu[2]
#     simu_y <- simu[3:(N + 2)]
#     input_data <- list("N" = N, "y" = simu_y)
#     capture.output(library(rstan))
#     capture.output(
#       fit <- sampling(fit_model, data = input_data, seed = 4938483)
#     )
#     util <- new.env()
#     source("stan_utility.R", local = util)
#     warning_code <- util$check_all_diagnostics(fit, quiet = TRUE)
#     sbc_rank_lambda <- sum(
#       simu_lambda < extract(fit)$lambda[seq(1, 4000 - 8, 8)]
#     )
#     sbc_rank_theta <- sum(simu_theta < extract(fit)$theta[seq(1, 4000 - 8, 8)])
#     s <- summary(fit, probs = c(), pars = "lambda")$summary
#     post_mean_lambda <- s[, 1]
#     post_sd_lambda <- s[, 3]
#     z_score_lambda <- (post_mean_lambda - simu_lambda) / post_sd_lambda
#     shrinkage_lambda <- 1 - (post_sd_lambda / prior_sd_lambda) ** 2
# 
#     s <- summary(fit, probs = c(), pars = "theta")$summary
#     post_mean_theta <- s[, 1]
#     post_sd_theta <- s[, 3]
#     z_score_theta <- (post_mean_theta - simu_theta) / post_sd_theta
#     shrinkage_theta <- 1 - (post_sd_theta / prior_sd_theta) ** 2
#     
#     c(warning_code, sbc_rank_lambda, z_score_lambda, shrinkage_lambda,
#       sbc_rank_theta, z_score_theta, shrinkage_theta)
#   }
# }, finally = {stopImplicitCluster()})
```
