---
title: "A deep dive into the Principled Workflow (using dplyr)"
author: "Giovanni d'Ario"
date: "9/15/2019"
output: html_document
---

```{r, echo=FALSE}
### Tidyverse libraries
library(magrittr)
library(tibble)
library(dplyr)
library(tidyr)
library(ggplot2)

### Parallel processing
library(foreach)
library(doParallel)

### rstan and utilities
library(rstan)
rstan_options(auto_write = TRUE)
util <- new.env()
source("stan_utility.R", local = util)

### My own utilities
source("utils.R")
```

# Introduction

In this document we try to break down the pattern described in the case study titled "Towards A Principled Bayesian Workflow". This pattern is repeated throughout the document, but the verbosity of the code can make it difficult to clearly identify the individual steps.

In this case study we assume that we are modeling measurements from an array of 100 detectors that are measuring the same source. We initially assume that the 100 detectors are identical. The workflow moves through 4 key steps:

1. Check the consistency of the prior predictive distribution with our domain knowledge.
2. Check computational faithfulness by plotting the Simulation Based Calibration histograms of the various parameters.
3. Check the model sensitivity by plotting the posterior z scores and the posterior shrinkage.
4. Check model adequacy by comparing our posterior predictive probability with the observations.

# Step 1: Domain Expertise Consistency

In model `sample_joint_ensemble.stan` we sample `lambda` from the prior, a Normal distribution with parameters $\mu = 0$ and $\sigma = 5.82337$, and we generate N  `y`s from a Poisson distribution with intensity `lambda`. We can generate these values in two ways. In the first case, we just fit the model and we obtain the values as parameters.

```{r}
R <- 1000 # 1000 draws from the Bayesian joint distribution
N <- 100

simu_data <- list("N" = N)

fit1 <- stan(file = 'sample_joint_ensemble.stan', data = simu_data,
            iter = R, warmup = 0, chains = 1, refresh = R,
            seed = 4838282, algorithm = "Fixed_param")
```

An alternative is to compile the model without actually fitting it, and running the `sampling` function from the `rstan` package to obtain the samples.

```{r using_sampling}
fit_model <- stan_model(file = "sample_joint_ensemble.stan")

fit2 <- sampling(fit_model, data = simu_data,
                 iter = R, warmup = 0, chains = 1, refresh = R,
                 seed = 4838282, algorithm = "Fixed_param")
```

This second form seems to offer some flexibility. No matter which fit we select, it contains simulated `lambda`s and `y`s.

```{r}
simu_params <- extract(fit1)
```

We can visualize the distribution of the values of `lambda` in a histogram.

```{r}
df_simu_ys <- data.frame(simu_params$y)
colnames(df_simu_ys) <- paste0("D", 1:100)
df_simu_ys$lambda <- simu_params$lambda

ggplot(df_simu_ys, aes(x = lambda)) + stat_bin(geom = "step")
```

This visualization, however, doesn't provide much of an insight into the model. Following the case study, we take the $1000 \times 100$ matrix containing the 1000 runs of our simulation and

1. For each *row* $r = 1,\ldots, 1000$ we bin the counts into a number of buckets $B$, thus obtaining a matrix $1000 \times B$.
2. For each *column*, i.e, each bin, we compute the deciles across the 1000 runs.
3. We plot the quantiles showing the median as a black line.

The `plot_bin_quantiles` function takes a matrix of `y`s and generates such plot. The gray line at $y = 25$ shows what, in the case study, is considered an extreme observation.

```{r}
print(dim(simu_params$y))
      
plot_bin_quantiles(simu_params$y) + 
  geom_vline(xintercept = 25, color = "darkgrey")
```

## Evaluate the simulated files

The output of the previous fit was a list of simulated parameters, `simu_params`. For the next step we want to rearrange this list into a matrix in order to take advantage of parallel computing by using the libraries `doParallel` and `foreach`.

The `simu_params` list contains three elements: `lambda`, `y` and `lp__`. The last element has to do with the log posterior, and we don't need it for our simulations. The utility function `create_simulation_matrix` removes such element and turns the list into a matrix. This matrix has 101 rows and 1000 columns. Each column corresponds to a run. The first row contains the simulated values for `lambda` while the remaining 100 contain the simulated values for the 100 values of `y`. We will be running 4 parallel processes, each of which does the following (most of these steps are performed by the `create_simulation_matrix` function):

1. Take a row of the matrix created by `create_simulation_matrix`. The first element of each row is the simulated value of `lambda`, while the remaining are the 100 values of `y`.
2. Create an `input_data` object containing the number of sensors $N$ and the 100 simulated `y`. These data will be then fed to a model `fit_model` based on a `fit_data.stan` file in order to compute the posteriors.
3. The model is fitted outside the `foreach` loop. Each parallel job samples from this model and returns the parameters for which we can estimate the posterior mean and standard deviation. During the sampling process, we also accumulate the diagnostic checks.
4. We compute the SBC ranks by means of the `get_sbc_ranks` function. This makes use of the simulated value of the parameter (the first row of our matrix) and of the posterior estimates we have just sampled. There is also a thinning parameter.
5. We compute the summary of the fitted parameters and compute the posterior mean and standard deviation. These are then used to compute the z-scores and the shrinkage.
6. To compute the shrinkage we also need the prior standard deviation. This must be passed explicitly by the user as an argument to `get_sbc_parameters`.
7. Finally, the `get_sbc_parmaeters` returns the warning codes, the SBC ranks, the z scores and the posterior shrinkage.

```{r}
tryCatch({
  ## Register doParallel
  registerDoParallel(cores = 4)
  
  ## Create a data frame of simulated lambdas and ys
  ## data.matrix converts a data frame into a matrix
  simu_matrix <- create_simulation_matrix(simu_params)

  ## Fit the model that computes the posterior density (we need to do it once).
  fit_model = stan_model(file = 'fit_data.stan')

  ensemble_output <- foreach(simu = simu_matrix, .combine = "cbind") %dopar% {
    get_sbc_parameters(sim_vector = simu,
                       model = fit_model,
                       param_names = "lambda",
                       prior_sd = 5.82337,
                       seed = 4938483,
                       N = N)
  }
}, finally = {stopImplicitCluster()})
```

The result is a 4 x 1000 matrix where the rows represent, in order, the number of warnings, the rank the z score, and the shrinkage for each of the $R$ runs.

```{r}
print(dim(ensemble_output))
rownames(ensemble_output) <- c("num_warnings", "sbc_rank", "z_score",
                               "shrinkage")
output_df <- data.frame(t(ensemble_output))
```

We can first check whether we have any warning message.

```{r}
sum(ensemble_output[1, ])
```

We have zero warnings. This is good. We can then plot a histogram of the SBC ranks using the same `breaks` as in the case study.

```{r}
ggplot(output_df, aes(sbc_rank)) +
  geom_histogram(color = c_dark_highlight, fill = c_dark,
                 breaks = seq(0, 500, 25) - 0.5) +
  xlab("Prior Rank") + ylab("")
```

Does it look like the histogram in the case study?

```{r}
sbc_hist <- hist(output_df$sbc_rank,
                 seq(0, 500, 25) - 0.5,
                 plot = FALSE)

plot(sbc_hist, main = "Lambda", xlab = "Prior Rank", yaxt = 'n', ylab = "")

low <- qbinom(0.005, R, 1 / 20)
mid <- qbinom(0.5, R, 1 / 20)
high <- qbinom(0.995, R, 1 / 20)
bar_x <- c(-10, 510, 500, 510,-10, 0,-10)
bar_y <- c(high, high, mid, low, low, mid, high)

polygon(bar_x, bar_y, col = c("#DDDDDD"), border = NA)
segments(x0 = 0, x1 = 500, y0 = mid, y1 = mid, col = c("#999999"), lwd = 2)

plot(sbc_hist, col = c_dark, border = c_dark_highlight, add = TRUE)
```

Yes, it does.

## Z scores and posterior shrinkage

We can plot the `z_score` vs the `shrinkage` and see where our simulations fall.

```{r}
ggplot(output_df, aes(x = shrinkage, y = z_score)) +
  geom_point(alpha = .1) +
  xlim(0, 1) + ylim(-4, 4)
```

**TO UNDERSTAND** how do you explain the shrinkage from the prior to the posterior?

## Fitting the observations an computing the posterior

The dataset consistes of 100 observations, one per detector.

```{r}
input_data <- read_rdump("workflow.data.R")
str(input_data)
```

We can then fit the observations with the following model

```{stan, eval=FALSE}
data {
  int<lower=0> N;
  int y[N];
}

parameters {
  real<lower=0> lambda;
}

model {
  lambda ~ normal(0, 5.82337);
  y ~ poisson(lambda);
}
```

```{r, message=FALSE}
fit <- stan(file = 'fit_data_ppc.stan', data = input_data, seed = 4938483)
```

```{r}
util$check_all_diagnostics(fit)
params <- extract(fit)
hist(params$lambda, main = "", xlab = "lambda", ylab = "",
     col = c_dark, border = c_dark_highlight)
```

## Analysis of the posterior predictive distribution

Running 4 chains has produced a 4000 x 100 matrix for `y_ppc`.

```{r}
p <- plot_bin_quantiles(params$y_ppc)
p + stat_bin(data = tibble(y_obs = input_data$y), aes(y_obs),
             breaks = 0:(41) - 0.5, geom = "step")
```

## Zero-inflated mode

The sampling model is stored in `sample_join_ensemble2.stan` while the data fitting model is in `fit_data2.stan`.

```{r}
fit <- stan(file = "sample_joint_ensemble2.stan", data = simu_data,
            iter = R, warmup = 0, chains = 1, refresh = R,
            seed = 4838282, algorithm = "Fixed_param")

simu_params <- extract(fit)
```

```{r}
plot_bin_quantiles(simu_params$y) +
  geom_vline(xintercept = 25, color = "darkgrey")
```

We can see the zero-enrichment in the prior predictive distribution, and the tails are unaltered.

## Simulated fits

```{r}
prior_sd_theta <- sqrt((2.8663**2) / (4*2.8663**2) * (2 * 2.8663 + 1))
prior_sd_lambda <- sqrt((9.21604)**2 / ((3.4681 - 1)**3))
  
tryCatch({
  ## Register doParallel
  registerDoParallel(cores = 4)
  
  ## Create a data frame of simulated lambdas and ys
  ## data.matrix converts a data frame into a matrix
  simu_list <- create_simulation_matrix(simu_params)

  ## Fit the model that computes the posterior density (we need to do it once).
  fit_model = stan_model(file = 'fit_data2.stan')

  ensemble_output <- foreach(simu = simu_list, .combine = "cbind") %dopar% {
    get_sbc_parameters(sim_vector = simu,
                       model = fit_model,
                       param_names = c("theta", "lambda"),
                       prior_sd = c(prior_sd_theta, prior_sd_lambda),
                       seed = 4938483,
                       N = N)
  }
}, finally = {stopImplicitCluster()})
```

Do we have warning codes? Yes we do:

```{r}
print(sum(ensemble_output[1, ]))
```

What kind of warnings do we get?

```{r what_warnings}
warning_code <- ensemble_output[1, ]
for (r in 1:R) {
  if (warning_code[r] != 0) {
    print(sprintf("Replication %s of %s", r, R))
    util$parse_warning_code(warning_code[r])
    print(sprintf("Simulated lambda = %s", simu_params$lambda[r]))
    print(sprintf("Simulated theta = %s", simu_params$theta[r]))
    print(" ")
  }
}
```

```{r fit_inv_gamma_simu}
fit <- stan(file = "sample_joint_ensemble3.stan", data = simu_data,
            iter = R, warmup = 0, chains = 1, refresh = R,
            seed = 4838282, algorithm = "Fixed_param")
simu_params <- rstan::extract(fit)
plot_bin_quantiles(simu_params$y, B = 70) +
  geom_vline(xintercept = 25, color = "darkgrey")
```


```{r}
prior_sd_theta <- sqrt(2.8663**2 / (4 * 2.8663**2 * (2 * 2.8663 + 1))) 
prior_sd_lambda <- sqrt((9.21604**2) / (3.48681 - 1)**3)

tryCatch({
  ## Register doParallel
  registerDoParallel(cores = 4)
  
  ## Create a data frame of simulated lambdas and ys
  ## data.matrix converts a data frame into a matrix
  simu_list <- create_simulation_matrix(simu_params)

  ## Fit the model that computes the posterior density (we need to do it once).
  fit_model = stan_model(file = 'fit_data3.stan')

  ensemble_output <- foreach(simu = simu_list, .combine = "cbind") %dopar% {
    get_sbc_parameters(sim_vector = simu,
                       model = fit_model,
                       param_names = c("theta", "lambda"),
                       prior_sd = c(prior_sd_theta, prior_sd_lambda),
                       seed = 4938483,
                       N = N)
  }
}, finally = {stopImplicitCluster()})
```
